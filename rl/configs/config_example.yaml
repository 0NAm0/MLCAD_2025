env:
  design_name: ac97_top
  work_dir: /workspace
  use_mock: false                                    // can change to false
  max_episode_len: 50
  actions_schema: rl/interfaces/actions.yaml
  qor_schema: rl/interfaces/qor_schema.yaml

reward:
  weights:
    wirelength: -1e-6
    power_dynamic: -0.1
    timing_slack: 1.0
  slack_penalty_if_negative: 1.0
  normalize:
    wirelength: {ref: 1.5e6, scale: 3.0e5}
    power_dynamic: {ref: 150.0, scale: 50.0}

trainer:
  total_steps: 1
  eval_interval: 1000
  save_interval: 2000
  max_episode_len: 50

agent:
  type: DQN
  gamma: 0.99
  lr: 0.0001        # learning rate
  batch_size: 64
  replay_size: 50000
  target_update_interval: 1000
  epsilon_start: 1.0
  epsilon_end: 0.05
  epsilon_decay_steps: 8000
